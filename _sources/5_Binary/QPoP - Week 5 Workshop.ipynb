{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3c80c1-0ef9-4b64-9b29-329166afdd07",
   "metadata": {},
   "source": [
    "## 5 - Binary outcome models\n",
    "### Dealing with non-continuous outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5962a64-6383-407c-9231-61c0f51b7e06",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This week we expand our linear model knowledge to deal with binary outcomes. That is - sticking to the mantra of 'all models are wrong, but some are useful', how can we best model and understand data that only ever takes on one of two values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde1efc-48ea-474b-a68b-4b3587004477",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Probit regression\n",
    "Probit regression solves this problem. Many of the same skills used for the GLM apply here, so we will spend some time fitting probit models using `statsmodels`, examining their probabilistic predictions with `marginaleffects`, and calculating some of thei varied statistics with other tools. \n",
    "\n",
    "Lets import everything we need for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa7166-c653-41a3-b1e0-ab7ec69ce9e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import most of what we need\n",
    "import pandas as pd # dataframes\n",
    "import seaborn as sns # plots\n",
    "import statsmodels.formula.api as smf # Models\n",
    "import marginaleffects as me # marginal effects\n",
    "\n",
    "# Set the style for plots\n",
    "sns.set_style('ticks') # a different theme!\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da7639-48b3-4661-b848-563357e0375f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Dichotomising data\n",
    "We will continue the example of working with the `affairs` dataset, but this time focusing on a binary outcome. First, we will load the dataset, and observe that the `affair` column has multiple distinct values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e472a-8069-4e61-8860-7f90816aab95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First read in the data\n",
    "affairs = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/AER/Affairs.csv')\n",
    "\n",
    "# Show top 3\n",
    "display(affairs.head(3))\n",
    "\n",
    "# Show the unique values in the affair columns\n",
    "print(affairs['affairs'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ffe493-5d40-427b-9851-f51218e09046",
   "metadata": {},
   "source": [
    "This suggests the majoirty of people have not had an affair, while a minority have had one or more. To use a probit regression here - to predict whether someone has, or has not, then we need to dichotomise the variable and put it back into the dataframe.\n",
    "\n",
    "A quick way of doing this is to borrow a function from a package called `numpy`, called `digitize`. This takes a column of a dataframe and a list of thresholds, and recodes the data such that equal to the threshold or more gets replaced with that value. \n",
    "\n",
    "Lets import `numpy` and recode the `affairs` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca149929-3a95-4393-b01e-f90063c1b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy with alias\n",
    "import numpy as np\n",
    "\n",
    "# Digitise the affairs column for 1 or more, put into a new column in the dataframe\n",
    "#affairs['affairyes'] = np.digitize(affairs['affairs'], [1])\n",
    "affairs['affairyes'] = np.where(affairs['affairs'].ge(1), 1, 0)\n",
    "\n",
    "# Scatter\n",
    "sns.pointplot(data=affairs, x='affairs', y='affairyes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a7789-8694-4747-8124-7dbcd9f0576c",
   "metadata": {},
   "source": [
    "### Fitting a model and making predictions\n",
    "With the new dichomotised variable, fitting a model is as simple as using `statsmodels` to use `probit` instead of `ols`. \n",
    "\n",
    "Below we predict occurrence of an affair from marriage rating, children, and years of marriage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843966f1-d3a5-4f36-9884-d4b2c5e444e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a probit model\n",
    "probit_model = smf.probit('affairyes ~ rating + yearsmarried + children',\n",
    "                          data=affairs).fit()\n",
    "\n",
    "# Show summary\n",
    "probit_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b43a2-5e4f-41c3-b3cc-0688d258f6c3",
   "metadata": {},
   "source": [
    "We can *roughly* interpret this outcome along the lines of those who are happier in their marriage move lower down the unobserved 'tendency to engage in an affair' variable, i.e., it reduces their probability of an affair. But by how much requires examining predictions - reasoning about coefficients in the GLM is hard, but with probit models it is even harder.\n",
    "\n",
    "Luckily, `marginaleffects` works exactly the same way. Lets have the model predict the probabilities of an affair for individuals with each level of marital satisfaction, just like with the GLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b39b3-a793-4b18-9eca-1d872552214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predict_for = me.datagrid(probit_model,\n",
    "                          rating=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Predictions\n",
    "predictions = me.predictions(probit_model, \n",
    "                             newdata=predict_for)\n",
    "\n",
    "# Display\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac8b11-a059-490e-89ae-1677c276b9b8",
   "metadata": {},
   "source": [
    "If we plot this we see the slightly non-linear relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9701b-171a-465a-a8b5-b7dbeab99ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "ax = sns.lineplot(data=predictions,\n",
    "                  x='rating', y='estimate')\n",
    "ax.set(ylabel='Predicted probability of affair')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3b99b-619c-4539-adf2-140459daad46",
   "metadata": {},
   "source": [
    "The predictions work in the same fashion as the GLM. For example, we can ask whether those with the highest satisfaction of 5 are less likely to have an affair than those with a 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e85fcb-2a30-4b14-8495-b6585b83971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast a 4 and 5\n",
    "me.predictions(probit_model, \n",
    "               newdata=me.datagrid(rating=[5, 4]),\n",
    "               hypothesis='pairwise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44552534-b2eb-4d69-b299-d11eb7d239b1",
   "metadata": {},
   "source": [
    "Those with a satisfaction of 5 have a lower probability of engaging in an affair of about 8 points, which is statistically significant. Notice how this number is totally divorced from the coefficients - in a GLM there would be *some* correspondence, but here, the predictions are absolutely essential. \n",
    "\n",
    "As a further example, consider the difference between those with a 1 and 2 on the satisfaction scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55abf5-3e39-49a5-b132-e6a1a456e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast a 1 and 2\n",
    "me.predictions(probit_model, \n",
    "               newdata=me.datagrid(rating=[2, 1]),\n",
    "               hypothesis='pairwise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa38590-5ae6-43b1-9c9d-9646ae5c0f9a",
   "metadata": {},
   "source": [
    "This is around 11 points - this is **not** the same as the 5 - 4 difference, which it would be in a GLM, because they are absolutely linear, while these models are not! The distinction is subtle but vital in interpretation, but since we are used to dealing with predictions, we need not worry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd6d36-ffd0-4dad-8d5e-ea0d43efef2c",
   "metadata": {},
   "source": [
    "### Checking fit and other statistics\n",
    "Lets see how to examine a range of statistics related to the fit of a probit model. \n",
    "\n",
    "#### The log-likelihood statistic\n",
    "First, the log-likelihood statistic, which shows us whether the predictors improve the predictions over a model with no predictors. This is stored in the `.summary()` output - a value closer to zero is better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578f678-363b-4b90-97d5-b45ed94bcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary, just first table\n",
    "probit_model.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc8753c-3a65-467a-8e50-4ba4ab35c31e",
   "metadata": {},
   "source": [
    "This is significant, offering us a coarse measure that our predictors, at least, aren't making things worse!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d07f6f-04fc-4705-8375-8eb50192dcf9",
   "metadata": {},
   "source": [
    "#### The phi coefficient\n",
    "This is the correlation between the observed values and predicted *binary* values. This takes a little bit of work to obtain, with the following steps:\n",
    "\n",
    "- Obtain the predicted probabilities of each datapoint\n",
    "- Convert them to 0 and 1 depending on whether they are below or above .5\n",
    "- Correlate them with the observed data, using the `corr` function from `pingouin`.\n",
    "\n",
    "We can do this in a few steps, relying on `marginaleffects` and the handy `np.digitize` function. \n",
    "\n",
    "First, get the predictions for each data point, then dichotomise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f8da9-d465-407a-8dd1-8256fb1f44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make a prediction on the whole dataset, like so\n",
    "all_predictions = me.predictions(probit_model) \n",
    "# notice there's nothing else here bar the model\n",
    "\n",
    "# Digitize with .5 as the threshold\n",
    "binary_predictions = np.digitize(all_predictions['estimate'],\n",
    "                                 [0.5])\n",
    "\n",
    "# Plot\n",
    "ax = sns.scatterplot(x=all_predictions['estimate'],\n",
    "                     y=binary_predictions,\n",
    "                     alpha=.5)\n",
    "ax.set(yticks=[0, 1],\n",
    "       ylabel='Predicted Affair Status',\n",
    "       xlabel='Predicted Probability of Affair')\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c21f2-29e9-49ce-a18c-f653ab03049f",
   "metadata": {},
   "source": [
    "Next, we import `pingouin` and carry out the correlation between the observed and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ef263-3d9e-40a9-aa01-d864b7d2a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pingouin\n",
    "import pingouin as pg\n",
    "\n",
    "# Correlate\n",
    "pg.corr(affairs['affairyes'],\n",
    "        binary_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee7873-b18e-45cf-96b4-fc1bfae1d956",
   "metadata": {},
   "source": [
    "Note the barely significant correlation here. The phi coefficient is not too promising, despite the other statistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156417f-b695-4aed-ab45-d0fda196d6a6",
   "metadata": {},
   "source": [
    "### The confusion matrix\n",
    "Now we have the binary predictions in hand, we can build the **confusion matrix** that lets us interpret the *types* of predictions the model has made. We can rely on `pandas` to help us figure this out, using the `pd.crosstab` function, which will neatly tabulate our results. All it needs is the actual data, and the predicted data, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23e44a-3250-4344-a084-58004fce87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstabs\n",
    "pd.crosstab(affairs['affairyes'],\n",
    "            binary_predictions,\n",
    "            rownames=['Observed'], # labels the rows\n",
    "            colnames=['Predicted'], # labels the columns\n",
    "            margins=True) # calculates the totals across rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8efa7f2-133e-4853-b23c-4d8adc37cde3",
   "metadata": {},
   "source": [
    "We can now see the explanation for the low phi coefficient. The model is making a lot of *false negative* predictions. That is, it is labelling those who have had an affair (150 in the data) as not having done so - out of the 150 who have, it thinks 143 did *not*, and only gets 7 correct!\n",
    "\n",
    "So as to dispel confusion about confusion matrices, here are the kinds of predictions this model has made:\n",
    "- **True negatives** - The model correctly predicted 0 for 443 people who did not have an affair, out of 451 who did not.\n",
    "- **True positives** - the model correctly predicted 1 for 7 people who did have an affair, out of 150 who did.\n",
    "- **False negatives** - the model incorrectly predicted 0 for 143 who did have an affair, out of the 150 who did.\n",
    "- **False positives** - the model incorrectly predicted 1 for 8 people who did not have an affair, out of the 451 who did.\n",
    "\n",
    "For a model designed to predict those who might engage in an affair, this is not great!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924a3c4-88c9-43a7-8438-f1d8c0ad31d1",
   "metadata": {},
   "source": [
    "### Building complexity in a probit model\n",
    "Having evaluated the model and found it lacking, lets try to improve it. One clear way is to increase the complexity by adding in interactions.\n",
    "\n",
    "Here we test a model that has a more complex story. We adjust for marital satisfaction ratings, but we include an interaction between years married, child status, and gender. This supposes that the propensity of an affair alters for how long a couple has been married and their child status, and that this pattern may be different for males and females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3aea3-d1b5-464d-876f-437054974db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a probit model\n",
    "probit_model2 = smf.probit('affairyes ~ rating + yearsmarried * children * gender',\n",
    "                          data=affairs).fit()\n",
    "\n",
    "# Show summary\n",
    "probit_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fb487-ee12-4d1a-afc2-1ba24f036c92",
   "metadata": {},
   "source": [
    "A few coefficients, including part of the interaction, are significant, and the log-likelihood ratio test is also.\n",
    "\n",
    "Let's make sense of this interaction step-by-step. First, we will generate and plot the predictions for a range of candidate years of marriage, for those with and without children, and for females and males:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831a56e-d840-4c90-8f5a-7079a26d71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "predict_this = me.datagrid(probit_model2,\n",
    "                           yearsmarried=np.arange(1, 25), # generates numbers 1 to 25\n",
    "                           children=['yes', 'no'],\n",
    "                           gender=['male', 'female'])\n",
    "\n",
    "# Get probabilities!\n",
    "probs = me.predictions(probit_model2, \n",
    "                       newdata=predict_this)\n",
    "\n",
    "# Plot\n",
    "g = sns.relplot(data=probs,\n",
    "                x='yearsmarried', y='estimate',\n",
    "                hue='children', col='gender',\n",
    "                kind='line', palette='magma')\n",
    "g.refline(y=0.5)\n",
    "g.set_ylabels('Predicted Probability of an Affair')\n",
    "g.set_xlabels('Years Married')\n",
    "g.set(xticks=[1, 5, 10, 15, 20, 25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd9e80-595f-4874-8b6e-2c5146f0c0b9",
   "metadata": {},
   "source": [
    "This suggests that while males and females *with* children have more or less a constant probability of an affair across their marriage duration, there is an increase in probabilities for those without children, and particularly for females.\n",
    "\n",
    "We can explore this further by examining the slopes of years married for females and males, with and without children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b630d-1365-424f-88af-3f3fef093a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slopes\n",
    "me.slopes(probit_model2,\n",
    "          newdata=predict_this,\n",
    "          variables='yearsmarried',\n",
    "          by=['gender', 'children'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d6ca6-22a0-4274-b543-4ee14f58f7ab",
   "metadata": {},
   "source": [
    "These demonstrate the slope (at its maximum point) for each combination of male, female, and child status.\n",
    "\n",
    "We can then test the hypotheses about whether these slopes are different using `hypothesis` methods. Is there a higher slope for females without children than with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850c306-76d7-4dee-9494-d8928e05258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hypothesis\n",
    "me.slopes(probit_model2,\n",
    "          newdata=predict_this,\n",
    "          variables='yearsmarried',\n",
    "          by=['gender', 'children'],\n",
    "          hypothesis='b1=b2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c69c5-4186-4fd1-a709-2870787cc63c",
   "metadata": {},
   "source": [
    "And for males:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b33a89-0211-483e-bf92-366826231060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second hypothesis\n",
    "me.slopes(probit_model2,\n",
    "          newdata=predict_this,\n",
    "          variables='yearsmarried',\n",
    "          by=['gender', 'children'],\n",
    "          hypothesis='b3=b4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a25324-47d3-44d2-a119-8108dd189d36",
   "metadata": {},
   "source": [
    "So an effect for females, not for males. Is the difference in these differences significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b4d67-6c48-49b2-8ec1-06e410de66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound hypothesis\n",
    "me.slopes(probit_model2,\n",
    "          newdata=predict_this,\n",
    "          variables='yearsmarried',\n",
    "          by=['gender', 'children'],\n",
    "          hypothesis='b1-b2 = b3-b4') # Females No - Yes = Male No - Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d206f-000b-40d8-ab8e-bb2f1e145d93",
   "metadata": {},
   "source": [
    "Almost; but not quite. But as we've seen, significance is not everything - we must also examine whether the model is doing a good job at predicting the data in terms of its classifications. First, we can compute the phi coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8256e45-a72e-4027-813d-a71a3ca08fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phi coeff\n",
    "# Predictions for all data\n",
    "all_predictions = me.predictions(probit_model2) \n",
    "\n",
    "# Digitize with .5 as the threshold\n",
    "binary_predictions = np.digitize(all_predictions['estimate'],\n",
    "                                 [0.5])\n",
    "\n",
    "# Correlate\n",
    "pg.corr(affairs['affairyes'], binary_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fabf975-f916-4e8c-99cd-5b009ef940bd",
   "metadata": {},
   "source": [
    "And the final check is to look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a6d2f-1f39-4e8e-ad70-9268f9b1911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "pd.crosstab(affairs['affairyes'],\n",
    "            binary_predictions,\n",
    "            rownames=['Observed'],\n",
    "            colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd030f-88ba-4f2f-8c43-6bac2bb09059",
   "metadata": {},
   "source": [
    "With these two extra pieces of information, its clear the model is not particularly good. Caution and circumspection is always warranted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
