
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7 - Linear mixed effects models &#8212; Statistical Modelling with Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '7_MixedModel/QPoP - Week 7 Workshop';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Quantitative Perspectives on Psychology" href="../6_Applications/QPoP%20-%20Week%206%20Exercises%20-%20Answers.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Statistical Modelling with Python - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Statistical Modelling with Python - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Statistical Modelling with Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Python Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1_Introduction/QPoP%20-%20Week%201%20Workshop.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../1_Introduction/QPoP%20-%20Week%201%20Exercises%20-%20Answers.html">Using Python for Data Analysis - Exercises &amp; Answers</a></li>






</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The GLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../2_The_GLM/QPoP%20-%20Week%202%20Workshop.html">2 - The General Linear Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2_The_GLM/QPoP%20-%20Week%202%20Exercises%20-%20Answers.html">Getting to grips with linear models in Python - Exercises &amp; Answers</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advancing the GLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../3_Advancing_GLM/QPoP%20-%20Week%203%20Workshop.html">3 - Advancing the general linear model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../3_Advancing_GLM/QPoP%20-%20Week%203%20Exercises%20-%20Answers.html">Checking assumptions and including interactions - Exercises &amp; Answers</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The art of prediction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_Prediction/QPoP%20-%20Week%204%20Workshop.html">4 - The art of prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_Prediction/QPoP%20-%20Week%204%20Exercises%20-%20Answers.html">Asking scientific questions of models - Exercises &amp; Answers</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Binary outcome models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../5_Binary/QPoP%20-%20Week%205%20Workshop.html">5 - Binary outcome models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../5_Binary/QPoP%20-%20Week%205%20Exercises%20-%20Answers.html">Using and understanding probit models - Exercises &amp; Answers</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Applications and other kinds of hypotheses</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../6_Applications/QPoP%20-%20Week%206%20Workshop.html">6 - Precision in Predictions</a></li>




<li class="toctree-l1"><a class="reference internal" href="../6_Applications/QPoP%20-%20Week%206%20Exercises%20-%20Answers.html">Quantitative Perspectives on Psychology</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Mixed Effects Models</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7 - Linear mixed effects models</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F7_MixedModel/QPoP - Week 7 Workshop.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/7_MixedModel/QPoP - Week 7 Workshop.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>7 - Linear mixed effects models</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7 - Linear mixed effects models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dealing-with-repeated-measurements">Dealing with repeated measurements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#professors-and-repeated-measurements">Professors and repeated measurements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-effects-how-mixed-models-work">Random effects - how mixed models work</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-intercepts">Random intercepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-intercepts-and-random-slopes">Random intercepts AND random slopes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-random-slope">The random slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-complexity-with-several-random-intercepts-and-random-slopes">Building complexity with several random intercepts and random slopes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-linear-mixed-models-to-identify-individual-differences">Using linear mixed models to identify individual differences</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-components-is-beauty-in-the-eye-of-the-beholder-or-a-property-of-faces">Variance components - is beauty in the eye of the beholder, or a property of faces?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions-with-mixed-models">Predictions with mixed models</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="linear-mixed-effects-models">
<h1>7 - Linear mixed effects models<a class="headerlink" href="#linear-mixed-effects-models" title="Link to this heading">#</a></h1>
<section id="dealing-with-repeated-measurements">
<h2>Dealing with repeated measurements<a class="headerlink" href="#dealing-with-repeated-measurements" title="Link to this heading">#</a></h2>
<p>This week we expand our modelling repertoire to deal with an important issue in psychology and behavioural science - what happens when you have repeated measurements in your data?</p>
<p>You might remember the <em>assumption of independent errors</em>. This subtle assumption means, simply, that a standard GLM expects each row of the data to be <strong>unrelated</strong> to the others. If this is the case, then each residual is also independent.</p>
<p>But very often in psychological datasets, we have <strong>repeated measurements</strong>, where participants are measured multiple times, or give us many responses on different variables. If we ignore this, we will end up biasing our coefficients, and by extension, altering our predictions and how sure we are about them.</p>
<p><strong>Linear mixed effects models</strong> allow us to deal with these kinds of data, and allow us to build complex models that allow us to investigate individual differences in a clear fashion when participants give us a lot of repeated data. How they do it can be confusing, but we can work through code-based examples to see how.</p>
<p>We need to import all our usual packages to investigate these models:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import what we need</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># dataframes</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> <span class="c1"># plots</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span> <span class="c1"># Models</span>
<span class="kn">import</span> <span class="nn">marginaleffects</span> <span class="k">as</span> <span class="nn">me</span> <span class="c1"># marginal effects</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># numpy for some functions</span>
<span class="kn">import</span> <span class="nn">statsmodels.tools.eval_measures</span> <span class="k">as</span> <span class="nn">measures</span>

<span class="c1"># Set the style for plots</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;whitegrid&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="professors-and-repeated-measurements">
<h2>Professors and repeated measurements<a class="headerlink" href="#professors-and-repeated-measurements" title="Link to this heading">#</a></h2>
<p>In an earlier example we investigated the effect of instructor attractiveness on teaching evaluations. At the time, we noted that this dataset actually violated the assumption of independent errors, but carried on in the interests of learning!</p>
<p>Now, we will use an appropriate model to examine this relationship in more detail, and see what happens if we actually meet this assumption - and show how to use them in practice. First lets read in the data and fit a standard GLM to it, which we know is incorrect:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read in data</span>
<span class="n">profs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://vincentarelbundock.github.io/Rdatasets/csv/AER/TeachingRatings.csv&#39;</span><span class="p">)</span>

<span class="c1"># Display data</span>
<span class="n">display</span><span class="p">(</span><span class="n">profs</span><span class="o">.</span><span class="n">head</span><span class="p">(),</span> <span class="n">profs</span><span class="o">.</span><span class="n">tail</span><span class="p">())</span>

<span class="c1"># Fit a GLM predicting evaluation from sex</span>
<span class="n">glm</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;eval ~ scale(beauty)&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">profs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">glm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">slim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rownames</th>
      <th>minority</th>
      <th>age</th>
      <th>gender</th>
      <th>credits</th>
      <th>beauty</th>
      <th>eval</th>
      <th>division</th>
      <th>native</th>
      <th>tenure</th>
      <th>students</th>
      <th>allstudents</th>
      <th>prof</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>yes</td>
      <td>36</td>
      <td>female</td>
      <td>more</td>
      <td>0.289916</td>
      <td>4.3</td>
      <td>upper</td>
      <td>yes</td>
      <td>yes</td>
      <td>24</td>
      <td>43</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>no</td>
      <td>59</td>
      <td>male</td>
      <td>more</td>
      <td>-0.737732</td>
      <td>4.5</td>
      <td>upper</td>
      <td>yes</td>
      <td>yes</td>
      <td>17</td>
      <td>20</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>no</td>
      <td>51</td>
      <td>male</td>
      <td>more</td>
      <td>-0.571984</td>
      <td>3.7</td>
      <td>upper</td>
      <td>yes</td>
      <td>yes</td>
      <td>55</td>
      <td>55</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>no</td>
      <td>40</td>
      <td>female</td>
      <td>more</td>
      <td>-0.677963</td>
      <td>4.3</td>
      <td>upper</td>
      <td>yes</td>
      <td>yes</td>
      <td>40</td>
      <td>46</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>no</td>
      <td>31</td>
      <td>female</td>
      <td>more</td>
      <td>1.509794</td>
      <td>4.4</td>
      <td>upper</td>
      <td>yes</td>
      <td>yes</td>
      <td>42</td>
      <td>48</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rownames</th>
      <th>minority</th>
      <th>age</th>
      <th>gender</th>
      <th>credits</th>
      <th>beauty</th>
      <th>eval</th>
      <th>division</th>
      <th>native</th>
      <th>tenure</th>
      <th>students</th>
      <th>allstudents</th>
      <th>prof</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>458</th>
      <td>459</td>
      <td>no</td>
      <td>32</td>
      <td>male</td>
      <td>more</td>
      <td>1.231394</td>
      <td>3.2</td>
      <td>lower</td>
      <td>yes</td>
      <td>yes</td>
      <td>9</td>
      <td>21</td>
      <td>93</td>
    </tr>
    <tr>
      <th>459</th>
      <td>460</td>
      <td>no</td>
      <td>32</td>
      <td>male</td>
      <td>more</td>
      <td>1.231394</td>
      <td>4.3</td>
      <td>upper</td>
      <td>yes</td>
      <td>yes</td>
      <td>52</td>
      <td>86</td>
      <td>93</td>
    </tr>
    <tr>
      <th>460</th>
      <td>461</td>
      <td>yes</td>
      <td>42</td>
      <td>female</td>
      <td>more</td>
      <td>0.420400</td>
      <td>3.3</td>
      <td>upper</td>
      <td>no</td>
      <td>yes</td>
      <td>52</td>
      <td>67</td>
      <td>94</td>
    </tr>
    <tr>
      <th>461</th>
      <td>462</td>
      <td>yes</td>
      <td>42</td>
      <td>female</td>
      <td>more</td>
      <td>0.420400</td>
      <td>3.2</td>
      <td>upper</td>
      <td>no</td>
      <td>yes</td>
      <td>54</td>
      <td>66</td>
      <td>94</td>
    </tr>
    <tr>
      <th>462</th>
      <td>463</td>
      <td>yes</td>
      <td>42</td>
      <td>female</td>
      <td>single</td>
      <td>0.420400</td>
      <td>4.1</td>
      <td>lower</td>
      <td>no</td>
      <td>yes</td>
      <td>28</td>
      <td>35</td>
      <td>94</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>      <td>eval</td>    <th>  R-squared:         </th> <td>   0.036</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.034</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   463</td>   <th>  F-statistic:       </th> <td>   17.08</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>4.25e-05</td>
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    3.9983</td> <td>    0.025</td> <td>  157.727</td> <td> 0.000</td> <td>    3.948</td> <td>    4.048</td>
</tr>
<tr>
  <th>scale(beauty)</th> <td>    0.1048</td> <td>    0.025</td> <td>    4.133</td> <td> 0.000</td> <td>    0.055</td> <td>    0.155</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>As before, we see significant effects of both gender and beauty. But if we look at the data display we can see the <code class="docutils literal notranslate"><span class="pre">prof</span></code> variable, which indicates which professor gave the class and is being evaluated, has multiple rows per professor - so we know our GLM is in trouble!</p>
<p>We can correct this by using the <code class="docutils literal notranslate"><span class="pre">mixedlm</span></code> command. We can do an awful lot of stuff with this command, fitting complex models with repeated measures data, but first lets see how to make a model aware that there are repeated measures:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using a mixed model</span>
<span class="n">mix</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">mixedlm</span><span class="p">(</span><span class="s1">&#39;eval ~ scale(beauty)&#39;</span><span class="p">,</span> <span class="c1"># formula is the same</span>
                  <span class="n">groups</span><span class="o">=</span><span class="s1">&#39;prof&#39;</span><span class="p">,</span> <span class="c1"># groups is the variable that &#39;keeps track&#39; of which row belongs to which professor - or whatever group!</span>
                  <span class="n">data</span><span class="o">=</span><span class="n">profs</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">mix</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>eval</td>   
</tr>
<tr>
  <td>No. Observations:</td>   <td>463</td>         <td>Method:</td>         <td>REML</td>   
</tr>
<tr>
     <td>No. Groups:</td>      <td>94</td>          <td>Scale:</td>         <td>0.1705</td>  
</tr>
<tr>
  <td>Min. group size:</td>     <td>1</td>      <td>Log-Likelihood:</td>   <td>-321.9997</td>
</tr>
<tr>
  <td>Max. group size:</td>    <td>13</td>        <td>Converged:</td>         <td>Yes</td>   
</tr>
<tr>
  <td>Mean group size:</td>    <td>4.9</td>            <td></td>               <td></td>     
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>        <th>Coef.</th> <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>
</tr>
<tr>
  <th>Intercept</th>     <td>3.929</td>   <td>0.045</td>  <td>88.145</td> <td>0.000</td>  <td>3.841</td>  <td>4.016</td>
</tr>
<tr>
  <th>scale(beauty)</th> <td>0.091</td>   <td>0.042</td>   <td>2.147</td> <td>0.032</td>  <td>0.008</td>  <td>0.174</td>
</tr>
<tr>
  <th>prof Var</th>      <td>0.139</td>   <td>0.075</td>     <td></td>      <td></td>       <td></td>       <td></td>   
</tr>
</table><br/>
</div></div>
</div>
<p>We can note several things from this output:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">No.</span> <span class="pre">Groups</span></code> - the model has identified there are 94 unique professors in the data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Min.</span> <span class="pre">group</span> <span class="pre">size</span></code> - this means there is at least one professor who had just one rating/course that was evaluated.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Max.</span> <span class="pre">group</span> <span class="pre">size</span></code> - this means there is at least one professor who had 13 ratings/courses that were evaluated.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Mean</span> <span class="pre">group</span> <span class="pre">size</span></code> - on average, each professor was rated 4.9 times.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Scale</span></code> - this is the <em>variance of the residuals</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prof</span> <span class="pre">Var</span></code> - there is now a new output! This interesting line tells us how much variation in our evaluation ratings is due to differences amongst professors - neat!</p></li>
</ol>
<p>Notice however that the coefficients are slightly different to the GLM - the mixed effects model has slightly different coefficients and wider intervals, and the <em>p</em>-values are different. This is only a simple example but the differences can be much larger in practice!</p>
<p>Is it worth all this extra stress though? If we examine the RMSE of both models we’ll see why it is…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># RMSE for both models</span>
<span class="n">glm_rmse</span> <span class="o">=</span> <span class="n">measures</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">glm</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">glm</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">)</span>
<span class="n">mix_rmse</span> <span class="o">=</span> <span class="n">measures</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">mix</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">mix</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;GLM RMSE: </span><span class="si">{</span><span class="n">glm_rmse</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;Mixed Model RMSE: </span><span class="si">{</span><span class="n">mix_rmse</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;GLM RMSE: 0.54&#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Mixed Model RMSE: 0.38&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-effects-how-mixed-models-work">
<h2>Random effects - how mixed models work<a class="headerlink" href="#random-effects-how-mixed-models-work" title="Link to this heading">#</a></h2>
<p>How do these models work? What do they do that allows us to incorporate the repeated measures?</p>
<p>They incorporate a clever statistical trick known as ‘random effects’, and these come in two types - a ‘random intercept’, and a ‘random slope’.</p>
<section id="random-intercepts">
<h3>Random intercepts<a class="headerlink" href="#random-intercepts" title="Link to this heading">#</a></h3>
<p>What is a random intercept? Quite simply, it is an <em>intercept estimated for each specific group in the data</em>. In our case, each professor gets their own intercept. While there is indeed a <em>global</em> intercept, each professor has their own, and they represent - compared to the global intercept - whether the professor is above or below on their teaching evaluations. Lets take a look at them:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Retrieve the intercepts - they are stored as a dictionary in the `.random_effects` attribute of the model. We can convert them into a DataFrame like so</span>
<span class="n">professor_effects</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">mix</span><span class="o">.</span><span class="n">random_effects</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">professor_effects</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># histogram of random effects</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">professor_effects</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prof</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.028885</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.219941</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.255526</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.140606</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.204728</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: ylabel=&#39;Count&#39;&gt;
</pre></div>
</div>
<img alt="../_images/f38066df9d8a9521f2a28e033fdccf0cc1a676d3ed4fa6fe1769e66ac1bd9572.png" src="../_images/f38066df9d8a9521f2a28e033fdccf0cc1a676d3ed4fa6fe1769e66ac1bd9572.png" />
</div>
</div>
<p>You can see they are centred around zero, because they are ‘offset’ from the global intercept. If we wanted to, we could add the global intercept to these, and obtain each professors actual intercept - same information, just represented differently.</p>
<p>The key thing to retain here is that the model is ‘figuring out’ multiple regression lines - in fact, one regression line per professor. They all have the same slope, but they all start from a different intercept point. Here’s a plot to visualise exactly what’s going on:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot all random effects and data</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="k">with</span> <span class="n">sns</span><span class="o">.</span><span class="n">plotting_context</span><span class="p">(</span><span class="s1">&#39;poster&#39;</span><span class="p">):</span>

    <span class="c1"># Canvas</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Data scatter</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">profs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;beauty&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

    <span class="c1"># Add the global line of best fit, which we obtain from predictions</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">me</span><span class="o">.</span><span class="n">predictions</span><span class="p">(</span><span class="n">mix</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;beauty&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;estimate&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Global Regression Line&#39;</span><span class="p">)</span>

    <span class="c1"># A bit of trickery to get each professors line!</span>
    <span class="k">for</span> <span class="n">intercept</span> <span class="ow">in</span> <span class="n">professor_effects</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> 
            <span class="p">(</span><span class="n">x</span> <span class="o">:=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">profs</span><span class="p">[</span><span class="s1">&#39;beauty&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">profs</span><span class="p">[</span><span class="s1">&#39;beauty&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)),</span>
            <span class="p">(</span><span class="n">mix</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">intercept</span><span class="o">.</span><span class="n">prof</span><span class="p">)</span> <span class="o">+</span> <span class="n">mix</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;scale(beauty)&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> 
            <span class="n">linewidth</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;An individual professor&#39;</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fe6b092dd3bd924b80adb08eb2acdda9aaac851dffd731fe562298318e6ef836.png" src="../_images/fe6b092dd3bd924b80adb08eb2acdda9aaac851dffd731fe562298318e6ef836.png" />
</div>
</div>
<p><em>This</em> is how the model deals with the assumption. It fits separate regression lines for each professor, who all have the same slope for beauty but have different intercepts.</p>
<p>The mathematics behind these models are very elegant, but we need not concern ourselves. We can think of it in two exchangeable ways:</p>
<ul class="simple">
<li><p>The model figures out a global intercept and then tries its best to provide a best-fitting offset for each person, or</p></li>
<li><p>The model gives everyone a single intercept and then averages them together as best it can to get the global intercept.</p></li>
</ul>
</section>
<section id="random-intercepts-and-random-slopes">
<h3>Random intercepts AND random slopes<a class="headerlink" href="#random-intercepts-and-random-slopes" title="Link to this heading">#</a></h3>
<p>While a random intercept is sufficient for us to fix the assumption of independent errors, there is far more to linear mixed models than just this. In the following example we’ll see how we can use their flexibility to map individual differences with intercepts and slopes. This is where things can get tricky, so we will take it slow.</p>
<p>We are going to examine data from a sleep-deprivation study, that illustrates how sleep restriction (~ 3 hours a night) affects reaction times on a task. Each participants reaction time was measured at baseline (day zero) before they started 9 days of sleep restriction. First, let us read in this data, and take a look at the structure:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read in sleep data and look at structure</span>
<span class="n">sleep</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://vincentarelbundock.github.io/Rdatasets/csv/lme4/sleepstudy.csv&#39;</span><span class="p">)</span>

<span class="c1"># Show top 15</span>
<span class="n">sleep</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rownames</th>
      <th>Reaction</th>
      <th>Days</th>
      <th>Subject</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>249.5600</td>
      <td>0</td>
      <td>308</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>258.7047</td>
      <td>1</td>
      <td>308</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>250.8006</td>
      <td>2</td>
      <td>308</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>321.4398</td>
      <td>3</td>
      <td>308</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>356.8519</td>
      <td>4</td>
      <td>308</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>414.6901</td>
      <td>5</td>
      <td>308</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>382.2038</td>
      <td>6</td>
      <td>308</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>290.1486</td>
      <td>7</td>
      <td>308</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>430.5853</td>
      <td>8</td>
      <td>308</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>466.3535</td>
      <td>9</td>
      <td>308</td>
    </tr>
    <tr>
      <th>10</th>
      <td>11</td>
      <td>222.7339</td>
      <td>0</td>
      <td>309</td>
    </tr>
    <tr>
      <th>11</th>
      <td>12</td>
      <td>205.2658</td>
      <td>1</td>
      <td>309</td>
    </tr>
    <tr>
      <th>12</th>
      <td>13</td>
      <td>202.9778</td>
      <td>2</td>
      <td>309</td>
    </tr>
    <tr>
      <th>13</th>
      <td>14</td>
      <td>204.7070</td>
      <td>3</td>
      <td>309</td>
    </tr>
    <tr>
      <th>14</th>
      <td>15</td>
      <td>207.7161</td>
      <td>4</td>
      <td>309</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Each participant thus provides about 11 days worth of reaction time data. If we were to analyse this with a GLM, our inferences and predictions would be incorrect, but a linear mixed model will be of great use. We can in fact plot the variation in reaction time, across days, for each participant, to give us a sense of what we’re trying to do:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot all data</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sleep</span><span class="p">,</span>
                  <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Reaction&#39;</span><span class="p">,</span> 
                  <span class="n">col_wrap</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                  <span class="n">s</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
                  <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                  <span class="n">col</span><span class="o">=</span><span class="s1">&#39;Subject&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/69240505735639f24e9ac0b769384de50597717468ab7148c2cd73daba5069d5.png" src="../_images/69240505735639f24e9ac0b769384de50597717468ab7148c2cd73daba5069d5.png" />
</div>
</div>
<p>As can be seen, there’s a lot of variability here. Lets first use the (incorrect) GLM to predict how reaction time changes with increasing time spent with poor sleep, and see how it looks:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># An incorrect GLM</span>
<span class="n">glm</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;Reaction ~ Days&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">sleep</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Get predictions, adding them to the dataset</span>
<span class="n">sleep</span><span class="p">[</span><span class="s1">&#39;glm_predictions&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">glm</span><span class="o">.</span><span class="n">fittedvalues</span><span class="c1"># an easy quick way of obtaining just the predictions, no extra bits</span>

<span class="c1"># Add the predictions to the plot</span>
<span class="n">fig2</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sleep</span><span class="p">,</span>
                   <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Reaction&#39;</span><span class="p">,</span> 
                   <span class="n">col_wrap</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                   <span class="n">s</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                   <span class="n">col</span><span class="o">=</span><span class="s1">&#39;Subject&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span> <span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="s1">&#39;glm_predictions&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/027d2461425aacc7d3626bfd26e90a6a20c736516429bac6e0eb704b838cef1b.png" src="../_images/027d2461425aacc7d3626bfd26e90a6a20c736516429bac6e0eb704b838cef1b.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># And take a look at the GLM output</span>
<span class="n">glm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">slim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>Reaction</td>  <th>  R-squared:         </th> <td>   0.286</td>
</tr>
<tr>
  <th>Model:</th>               <td>OLS</td>    <th>  Adj. R-squared:    </th> <td>   0.282</td>
</tr>
<tr>
  <th>No. Observations:</th>  <td>   180</td>   <th>  F-statistic:       </th> <td>   71.46</td>
</tr>
<tr>
  <th>Covariance Type:</th>  <td>nonrobust</td> <th>  Prob (F-statistic):</th> <td>9.89e-15</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>  251.4051</td> <td>    6.610</td> <td>   38.033</td> <td> 0.000</td> <td>  238.361</td> <td>  264.449</td>
</tr>
<tr>
  <th>Days</th>      <td>   10.4673</td> <td>    1.238</td> <td>    8.454</td> <td> 0.000</td> <td>    8.024</td> <td>   12.911</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>As can be seen above, <em>the line is exactly the same for each person</em>. The GLM is blind to the fact each person has different data, and so we should not trust the results.</p>
<p>We can add a random intercept to this data as we did for the professor dataset, by telling the <code class="docutils literal notranslate"><span class="pre">mixedlm</span></code> command the name of the “group” variable - that is, the <code class="docutils literal notranslate"><span class="pre">Subject</span></code> column. How does that look?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit a mixed model with a random intercept</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">mixedlm</span><span class="p">(</span><span class="s1">&#39;Reaction ~ Days&#39;</span><span class="p">,</span> 
                        <span class="n">groups</span><span class="o">=</span><span class="s1">&#39;Subject&#39;</span><span class="p">,</span>
                        <span class="n">data</span><span class="o">=</span><span class="n">sleep</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Get the predictions</span>
<span class="n">sleep</span><span class="p">[</span><span class="s1">&#39;intercept_predictions&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">intercept</span><span class="o">.</span><span class="n">fittedvalues</span>

<span class="c1"># Add the predictions to the plot</span>
<span class="n">fig2</span> <span class="o">=</span> <span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sleep</span><span class="p">,</span>
                    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Reaction&#39;</span><span class="p">,</span> 
                    <span class="n">col_wrap</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                    <span class="n">col</span><span class="o">=</span><span class="s1">&#39;Subject&#39;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span> <span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="s1">&#39;glm_predictions&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GLM&#39;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span> <span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept_predictions&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mixed Model - Intercepts&#39;</span><span class="p">)</span>
         <span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0f0d8f1a622ffa12082325161106693e1aff1cd960abd6d6d4d077bc73a82a19.png" src="../_images/0f0d8f1a622ffa12082325161106693e1aff1cd960abd6d6d4d077bc73a82a19.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># And take a look at the model summary</span>
<span class="n">intercept</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td> <td>Reaction</td> 
</tr>
<tr>
  <td>No. Observations:</td>   <td>180</td>         <td>Method:</td>         <td>REML</td>   
</tr>
<tr>
     <td>No. Groups:</td>      <td>18</td>          <td>Scale:</td>        <td>960.4568</td> 
</tr>
<tr>
  <td>Min. group size:</td>    <td>10</td>      <td>Log-Likelihood:</td>   <td>-893.2325</td>
</tr>
<tr>
  <td>Max. group size:</td>    <td>10</td>        <td>Converged:</td>         <td>Yes</td>   
</tr>
<tr>
  <td>Mean group size:</td>   <td>10.0</td>            <td></td>               <td></td>     
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>         <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> 
</tr>
<tr>
  <th>Intercept</th>    <td>251.405</td>   <td>9.747</td>  <td>25.794</td> <td>0.000</td> <td>232.302</td> <td>270.508</td>
</tr>
<tr>
  <th>Days</th>         <td>10.467</td>    <td>0.804</td>  <td>13.015</td> <td>0.000</td>  <td>8.891</td>  <td>12.044</td> 
</tr>
<tr>
  <th>Subject Var</th> <td>1378.176</td>  <td>17.156</td>     <td></td>      <td></td>       <td></td>        <td></td>    
</tr>
</table><br/>
</div></div>
</div>
<p>Notice how the intercepts in the graph alter, but not the slopes. Participant 369 has little difference for example - but the varying intercepts allow better predictions for Participant 337 and 352. The model is now ‘aware’ of the differences and has incorporated them. Also notice that the results here are relatively unchanged! The coefficients are broadly similar and are always significant - but the <em>quality</em> of the mixed model predictions are clearly more accurate!</p>
</section>
</section>
<section id="the-random-slope">
<h2>The random slope<a class="headerlink" href="#the-random-slope" title="Link to this heading">#</a></h2>
<p>Now for the crowning glory - while we can include random intercepts for all our participants, we can also include a <em>random slope</em>. This means we can let the slope of Day vary for each person (or indeed, any other predictor). This requires us to modify our <code class="docutils literal notranslate"><span class="pre">mixedlm</span></code> command a little. We now include the <code class="docutils literal notranslate"><span class="pre">re_formula</span></code> keyword, and pass it the name of the column we’d like to have the slopes for, as shown below. Note that this also includes the random intercepts - only in very rare circumstances would you exclude intercepts and fit only random slopes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Our final model</span>
<span class="n">slopes</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">mixedlm</span><span class="p">(</span><span class="s1">&#39;Reaction ~ Days&#39;</span><span class="p">,</span> 
                     <span class="n">groups</span><span class="o">=</span><span class="s1">&#39;Subject&#39;</span><span class="p">,</span>
                     <span class="n">re_formula</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="c1"># Where the magic happens</span>
                     <span class="n">data</span><span class="o">=</span><span class="n">sleep</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Extract predictions</span>
<span class="n">sleep</span><span class="p">[</span><span class="s1">&#39;slope_predictions&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">slopes</span><span class="o">.</span><span class="n">fittedvalues</span>

<span class="c1"># And show</span>
<span class="n">fig3</span> <span class="o">=</span> <span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">relplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sleep</span><span class="p">,</span>
                    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Reaction&#39;</span><span class="p">,</span> 
                    <span class="n">col_wrap</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
                    <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                    <span class="n">col</span><span class="o">=</span><span class="s1">&#39;Subject&#39;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span> <span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="s1">&#39;glm_predictions&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GLM&#39;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span> <span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="s1">&#39;intercept_predictions&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mixed Model - Intercepts&#39;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">,</span> <span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="s1">&#39;slope_predictions&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Mixed Model - Intercepts + Slopes&#39;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">add_legend</span><span class="p">()</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d9d834dbc315d22dc18706f02222c726e998bd4a45fd694dbac37320562a871f.png" src="../_images/d9d834dbc315d22dc18706f02222c726e998bd4a45fd694dbac37320562a871f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check the output</span>
<span class="n">slopes</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td> <td>Reaction</td> 
</tr>
<tr>
  <td>No. Observations:</td>   <td>180</td>         <td>Method:</td>         <td>REML</td>   
</tr>
<tr>
     <td>No. Groups:</td>      <td>18</td>          <td>Scale:</td>        <td>654.9405</td> 
</tr>
<tr>
  <td>Min. group size:</td>    <td>10</td>      <td>Log-Likelihood:</td>   <td>-871.8141</td>
</tr>
<tr>
  <td>Max. group size:</td>    <td>10</td>        <td>Converged:</td>         <td>Yes</td>   
</tr>
<tr>
  <td>Mean group size:</td>   <td>10.0</td>            <td></td>               <td></td>     
</tr>
</table>
<table class="simpletable">
<tr>
           <td></td>           <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> 
</tr>
<tr>
  <th>Intercept</th>          <td>251.405</td>   <td>6.825</td>  <td>36.838</td> <td>0.000</td> <td>238.029</td> <td>264.781</td>
</tr>
<tr>
  <th>Days</th>               <td>10.467</td>    <td>1.546</td>   <td>6.771</td> <td>0.000</td>  <td>7.438</td>  <td>13.497</td> 
</tr>
<tr>
  <th>Subject Var</th>        <td>612.096</td>  <td>11.881</td>     <td></td>      <td></td>       <td></td>        <td></td>    
</tr>
<tr>
  <th>Subject x Days Cov</th>  <td>9.605</td>    <td>1.821</td>     <td></td>      <td></td>       <td></td>        <td></td>    
</tr>
<tr>
  <th>Days Var</th>           <td>35.072</td>    <td>0.610</td>     <td></td>      <td></td>       <td></td>        <td></td>    
</tr>
</table><br/>
</div></div>
</div>
<p>The random slopes and intercepts together improve the predictions overall, correcting many of errors that the random intercepts miss. Consider participants 308 and 309 - while the blue line does its best to fit their data, only by altering the slope can we properly account for their reaction time increases. Notice again the output of this model is, for all intents and purposes, the same as in the GLM! The coefficients are still signifcant and similar in size. Does this mean that model is just as good? No! Model structure is far more important than <em>p</em>-values. The RMSE of the models is revealing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># RMSE</span>
<span class="n">display</span><span class="p">(</span>
    <span class="s1">&#39;GLM RMSE: &#39;</span><span class="p">,</span> <span class="n">measures</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">glm</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">glm</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">),</span>
    <span class="s1">&#39;Mixed Model Intercepts Only RMSE: &#39;</span><span class="p">,</span> <span class="n">measures</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">intercept</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">intercept</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">),</span>
    <span class="s1">&#39;Mixed Model Intercepts + Slopes RMSE: &#39;</span><span class="p">,</span> <span class="n">measures</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">slopes</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">endog</span><span class="p">,</span> <span class="n">slopes</span><span class="o">.</span><span class="n">fittedvalues</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;GLM RMSE: &#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>47.448897509757494
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Mixed Model Intercepts Only RMSE: &#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>29.41062417621592
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Mixed Model Intercepts + Slopes RMSE: &#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>23.43805168478719
</pre></div>
</div>
</div>
</div>
<p>Note also the extra information present in the output of the model above. The <code class="docutils literal notranslate"><span class="pre">Subject</span> <span class="pre">Var</span></code> and <code class="docutils literal notranslate"><span class="pre">Days</span> <span class="pre">Var</span></code> rows tell us how much variance people alone contribute to the overall reaction time variation, and how much the variation between people there is in how they change over each day, respectively. One is far higher than the other - this suggests that people are more variable in their baseline reaction time than the effect of poor sleep is on changing that. It’s also possible to do very advanced analyses such as correlating the random effects - that is, we can obtain each participants random intercept and slope, and correlate them, like so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Obtain random effects in a dataframe</span>
<span class="n">ranefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">slopes</span><span class="o">.</span><span class="n">random_effects</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">ranefs</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span>
        <span class="n">ranefs</span><span class="o">.</span><span class="n">corr</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Subject</th>
      <th>Days</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>308</th>
      <td>2.258584</td>
      <td>9.198969</td>
    </tr>
    <tr>
      <th>309</th>
      <td>-40.398695</td>
      <td>-8.619686</td>
    </tr>
    <tr>
      <th>310</th>
      <td>-38.960356</td>
      <td>-5.448864</td>
    </tr>
    <tr>
      <th>330</th>
      <td>23.690554</td>
      <td>-4.814339</td>
    </tr>
    <tr>
      <th>331</th>
      <td>22.260257</td>
      <td>-3.069902</td>
    </tr>
    <tr>
      <th>332</th>
      <td>9.039549</td>
      <td>-0.272174</td>
    </tr>
    <tr>
      <th>333</th>
      <td>16.840475</td>
      <td>-0.223631</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Subject</th>
      <th>Days</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Subject</th>
      <td>1.000000</td>
      <td>0.263547</td>
    </tr>
    <tr>
      <th>Days</th>
      <td>0.263547</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Subject&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Days&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">ranefs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;Subject&#39;, ylabel=&#39;Days&#39;&gt;
</pre></div>
</div>
<img alt="../_images/90c78602ccdebdc6fb0e95a48d1b16617de5a7e40c199baa29343d07a3ac84f4.png" src="../_images/90c78602ccdebdc6fb0e95a48d1b16617de5a7e40c199baa29343d07a3ac84f4.png" />
</div>
</div>
<p>This suggest those with higher starting baselines (i.e., are slower to start with) show bigger increases in their reaction times with more time spent sleep deprived.</p>
</section>
<section id="building-complexity-with-several-random-intercepts-and-random-slopes">
<h2>Building complexity with several random intercepts and random slopes<a class="headerlink" href="#building-complexity-with-several-random-intercepts-and-random-slopes" title="Link to this heading">#</a></h2>
<section id="using-linear-mixed-models-to-identify-individual-differences">
<h3>Using linear mixed models to identify individual differences<a class="headerlink" href="#using-linear-mixed-models-to-identify-individual-differences" title="Link to this heading">#</a></h3>
<p>We turn now to a more complex example and push the capabilities of <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>. About ten years ago I was researching the effects of cosmetics on attractiveness as part of a collaboration with industry. One of the things our partners were interested in was how cosmetics impacted models differently - e.g., do some people get a bigger benefit from makeup than others, and how does that depend on their initial level of attractiveness? e.g. one might imagine more attractive models gain ‘less’ from cosmetics than do less attractive models. We didn’t realise it at the time, but a linear mixed model would allow us to answer this question easily (in fact, it was not so easy to fit these models ten years ago!). The original paper is <a class="reference external" href="https://alexjonesphd.github.io/assets/papers/2016/jones_kramer_2016.pdf">here</a>.</p>
<p>To test this, we had a set of participants rate around 45 models for attractiveness, photographed with and without cosmetics. Our model is thus very simple, actually much like a t-test - <code class="docutils literal notranslate"><span class="pre">ratings</span> <span class="pre">~</span> <span class="pre">cosmetics</span></code> - how much does attractiveness change with makeup?</p>
<p>However, there are many sources of variability we didn’t properly control for in this data.</p>
<ul class="simple">
<li><p>The first is the variability from <em>participants</em>, who will vary in how much they like the models. In fact we simply removed this variability by averaging - a terrible decision in hindsight. We can incorporate this as a random intercept for participants.</p></li>
<li><p>The second is the baseline level of attractiveness of each model. That is, how much more or less attractive than the average is each model? This can be incorporated as a random intercept for models - notice now we have <strong>two</strong> random intercepts!</p></li>
<li><p>The third is the effect of cosmetics on each model. That is, how much does the attractiveness of each model change with an application of cosmetics? In our initial analysis we addressed this in a very roundabout, indirect way. But with mixed models, this is simply incorporated as a random slope for cosmetics <em>for each model</em>.</p></li>
</ul>
<p>Let’s see if our conclusions hold when we use a proper model. To do this will involve some extra steps to coerce the model to fit. First, lets read in the data and take a look at it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read in data</span>
<span class="n">cosmetics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/alexjonesphd/py4psy2024/refs/heads/main/jones_kramer_2015.csv&#39;</span><span class="p">)</span>

<span class="c1"># Show top 10 rows</span>
<span class="n">display</span><span class="p">(</span><span class="n">cosmetics</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pid</th>
      <th>model_id</th>
      <th>cosmetics</th>
      <th>rating</th>
      <th>cosmetics_code</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>44</td>
      <td>1</td>
      <td>without</td>
      <td>2</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44</td>
      <td>2</td>
      <td>with</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>44</td>
      <td>3</td>
      <td>without</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>44</td>
      <td>4</td>
      <td>without</td>
      <td>3</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>44</td>
      <td>5</td>
      <td>without</td>
      <td>3</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">pid</span></code> column represents the participant, <code class="docutils literal notranslate"><span class="pre">model_id</span></code> is the model identifier, the <code class="docutils literal notranslate"><span class="pre">cosmetics</span></code> and <code class="docutils literal notranslate"><span class="pre">cosmetics_code</span></code> columns show whether the instance was presented with/without makeup, and <code class="docutils literal notranslate"><span class="pre">rating</span></code> is the attractiveness rating assigned by that participant, to that model, in that makeup condition. We can visualise the overall pattern:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show overall</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pointplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cosmetics</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;cosmetics&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;rating&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;cosmetics&#39;, ylabel=&#39;rating&#39;&gt;
</pre></div>
</div>
<img alt="../_images/c9357c12a9fe46d99787de3c93fdb93409be928b025434f535e567e0ebb38d1a.png" src="../_images/c9357c12a9fe46d99787de3c93fdb93409be928b025434f535e567e0ebb38d1a.png" />
</div>
</div>
<p>But this ignores the variability in the dataset from models and participants. Lets see how we can fit the structured model.</p>
<p>To do this we must use an approach called <strong>variance components</strong>, which allows us to directly tell the model which ratings belong to which source (e.g., model, participant). The first step is to create a new variable that is the same number for everyone, that is, our grouping variable is the same for all data - we then can partition it up. This is easy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a variable with a single number for everyone</span>
<span class="n">cosmetics</span><span class="p">[</span><span class="s1">&#39;grouping&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Show</span>
<span class="n">display</span><span class="p">(</span><span class="n">cosmetics</span><span class="o">.</span><span class="n">head</span><span class="p">(),</span> <span class="n">cosmetics</span><span class="o">.</span><span class="n">tail</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pid</th>
      <th>model_id</th>
      <th>cosmetics</th>
      <th>rating</th>
      <th>cosmetics_code</th>
      <th>grouping</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>44</td>
      <td>1</td>
      <td>without</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44</td>
      <td>2</td>
      <td>with</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>44</td>
      <td>3</td>
      <td>without</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>44</td>
      <td>4</td>
      <td>without</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>44</td>
      <td>5</td>
      <td>without</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pid</th>
      <th>model_id</th>
      <th>cosmetics</th>
      <th>rating</th>
      <th>cosmetics_code</th>
      <th>grouping</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2998</th>
      <td>30</td>
      <td>29</td>
      <td>without</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2999</th>
      <td>30</td>
      <td>30</td>
      <td>with</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3000</th>
      <td>30</td>
      <td>31</td>
      <td>with</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3001</th>
      <td>30</td>
      <td>32</td>
      <td>without</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3002</th>
      <td>30</td>
      <td>33</td>
      <td>with</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Literally every row now has a ‘1’ in it. That’s our grouping variable. Next, we have to use some curious syntax to specify our random effects.</p>
<p>We do this via a dictionary, and we give each source of variability a name. Then we use different expressions to indicate a random intercept or slope.</p>
<ul class="simple">
<li><p>A random intercept would look like this: <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">+</span> <span class="pre">C(variable_name)</span></code> - we add a ‘C’ around the name to force Python to recognise it as a categorical variable.</p></li>
<li><p>A random slope would look like this: <code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">+</span> <span class="pre">C(variable_name):predictor_name</span></code>. This is like saying ‘there needs to be a random slope of <code class="docutils literal notranslate"><span class="pre">predictor_name</span></code> for each individual in the <code class="docutils literal notranslate"><span class="pre">variable_name</span></code> group’.</p></li>
</ul>
<p>We want to have a random intercept for participants and models, and a random slope of cosmetics for each model, so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># random effects</span>
<span class="n">re</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pid&#39;</span><span class="p">:</span> <span class="s1">&#39;0 + C(pid)&#39;</span><span class="p">,</span> 
      <span class="s1">&#39;model_id&#39;</span><span class="p">:</span> <span class="s1">&#39;0 + C(model_id)&#39;</span><span class="p">,</span>
      <span class="s1">&#39;cosmetics_model&#39;</span><span class="p">:</span> <span class="s1">&#39;0 + C(model_id):cosmetics_code&#39;</span><span class="p">}</span> 
</pre></div>
</div>
</div>
</div>
<p>Then we specify them in our model (as well as our fixed grouping factor) like so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit our fancy model</span>
<span class="n">cosmetics_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">mixedlm</span><span class="p">(</span><span class="s1">&#39;rating ~ cosmetics_code&#39;</span><span class="p">,</span>
                              <span class="n">groups</span><span class="o">=</span><span class="s1">&#39;grouping&#39;</span><span class="p">,</span> <span class="c1"># the constant grouping number</span>
                              <span class="n">vc_formula</span><span class="o">=</span><span class="n">re</span><span class="p">,</span> <span class="c1"># the dictionary of vc</span>
                              <span class="n">data</span><span class="o">=</span><span class="n">cosmetics</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Show the results</span>
<span class="n">cosmetics_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>rating</td>  
</tr>
<tr>
  <td>No. Observations:</td>  <td>3003</td>         <td>Method:</td>          <td>REML</td>   
</tr>
<tr>
     <td>No. Groups:</td>       <td>1</td>          <td>Scale:</td>          <td>1.5169</td>  
</tr>
<tr>
  <td>Min. group size:</td>   <td>3003</td>     <td>Log-Likelihood:</td>   <td>-5083.8173</td>
</tr>
<tr>
  <td>Max. group size:</td>   <td>3003</td>       <td>Converged:</td>          <td>Yes</td>   
</tr>
<tr>
  <td>Mean group size:</td>  <td>3003.0</td>           <td></td>                <td></td>     
</tr>
</table>
<table class="simpletable">
<tr>
           <td></td>           <th>Coef.</th> <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>
</tr>
<tr>
  <th>Intercept</th>           <td>3.240</td>   <td>0.149</td>  <td>21.809</td> <td>0.000</td>  <td>2.949</td>  <td>3.531</td>
</tr>
<tr>
  <th>cosmetics_code</th>      <td>1.162</td>   <td>0.132</td>   <td>8.778</td> <td>0.000</td>  <td>0.902</td>  <td>1.421</td>
</tr>
<tr>
  <th>cosmetics_model Var</th> <td>0.509</td>   <td>0.118</td>     <td></td>      <td></td>       <td></td>       <td></td>   
</tr>
<tr>
  <th>model_id Var</th>        <td>0.549</td>   <td>0.119</td>     <td></td>      <td></td>       <td></td>       <td></td>   
</tr>
<tr>
  <th>pid Var</th>             <td>0.401</td>   <td>0.055</td>     <td></td>      <td></td>       <td></td>       <td></td>   
</tr>
</table><br/>
</div></div>
</div>
<p>Our model shows the mean difference between cosmetics conditions is significant. The <code class="docutils literal notranslate"><span class="pre">with</span></code> condition, on average, is about 1.162 units higher than the without.</p>
<p>It’s now possible to check the variance the model calculates to answer part of our initial question. We can add up all the sources of variability in the model:</p>
<ol class="arabic simple">
<li><p>Cosmetics (due to the random slope)</p></li>
<li><p>Model (variation due to baseline attractiveness of models)</p></li>
<li><p>PID (variation due to participants having different tastes)</p></li>
<li><p>Scale (unexplained variation/error).</p></li>
</ol>
<p>If we add those up and then take a single measure and divide-by-the-total, we’ll see how much it contributes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get total variance by adding the vcomp + scale together</span>
<span class="n">total_variance</span> <span class="o">=</span> <span class="n">cosmetics_model</span><span class="o">.</span><span class="n">vcomp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">cosmetics_model</span><span class="o">.</span><span class="n">scale</span>

<span class="c1"># How much is due to makeup altering faces differently?</span>
<span class="n">makeup</span> <span class="o">=</span> <span class="mf">0.509</span> <span class="o">/</span> <span class="n">total_variance</span>

<span class="c1"># How much is due to models varying in attractiveness?</span>
<span class="n">models</span> <span class="o">=</span> <span class="mf">0.549</span> <span class="o">/</span> <span class="n">total_variance</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Due to makeup: </span><span class="si">{</span><span class="n">makeup</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%, due to models: </span><span class="si">{</span><span class="n">models</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Due to makeup: 0.17%, due to models: 0.18%
</pre></div>
</div>
</div>
</div>
<p>Oh dear. Our last line of the abstract was ‘…However, the effect of individual differences in facial appearance is ultimately more important in perceptions of attractiveness’. That’s flat wrong. It appears both of these things contribute similarly to the overall attractiveness effect!</p>
<p>One additional step is to correlate the intercepts and slopes for each model. Getting these is a bit tricky, but can be done like so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get all random effects</span>
<span class="n">ranefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">cosmetics_model</span><span class="o">.</span><span class="n">random_effects</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>

<span class="c1"># Show</span>
<span class="n">ranefs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cosmetics_model[C(model_id)[1]:cosmetics_code]</th>
      <td>0.361547</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[2]:cosmetics_code]</th>
      <td>0.602184</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[3]:cosmetics_code]</th>
      <td>-0.586605</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[4]:cosmetics_code]</th>
      <td>0.849587</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[5]:cosmetics_code]</th>
      <td>-0.150157</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>pid[C(pid)[100]]</th>
      <td>-1.020414</td>
    </tr>
    <tr>
      <th>pid[C(pid)[103]]</th>
      <td>-0.726942</td>
    </tr>
    <tr>
      <th>pid[C(pid)[106]]</th>
      <td>-0.296678</td>
    </tr>
    <tr>
      <th>pid[C(pid)[109]]</th>
      <td>0.925090</td>
    </tr>
    <tr>
      <th>pid[C(pid)[112]]</th>
      <td>-0.103292</td>
    </tr>
  </tbody>
</table>
<p>157 rows × 1 columns</p>
</div></div></div>
</div>
<p>We’ll have to filter this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get slopes</span>
<span class="n">slopes</span> <span class="o">=</span> <span class="n">ranefs</span><span class="p">[</span><span class="n">ranefs</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;cosmetics_code&#39;</span><span class="p">)]</span>

<span class="c1"># Intercepts</span>
<span class="n">intercepts</span> <span class="o">=</span> <span class="n">ranefs</span><span class="p">[</span><span class="o">~</span><span class="n">ranefs</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;pid|cosmetics&#39;</span><span class="p">)]</span>

<span class="c1"># Display</span>
<span class="n">display</span><span class="p">(</span><span class="n">slopes</span><span class="o">.</span><span class="n">head</span><span class="p">(),</span> <span class="n">intercepts</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>cosmetics_model[C(model_id)[1]:cosmetics_code]</th>
      <td>0.361547</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[2]:cosmetics_code]</th>
      <td>0.602184</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[3]:cosmetics_code]</th>
      <td>-0.586605</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[4]:cosmetics_code]</th>
      <td>0.849587</td>
    </tr>
    <tr>
      <th>cosmetics_model[C(model_id)[5]:cosmetics_code]</th>
      <td>-0.150157</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>model_id[C(model_id)[1]]</th>
      <td>-0.901041</td>
    </tr>
    <tr>
      <th>model_id[C(model_id)[2]]</th>
      <td>0.491351</td>
    </tr>
    <tr>
      <th>model_id[C(model_id)[3]]</th>
      <td>1.245916</td>
    </tr>
    <tr>
      <th>model_id[C(model_id)[4]]</th>
      <td>0.007135</td>
    </tr>
    <tr>
      <th>model_id[C(model_id)[5]]</th>
      <td>0.219817</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can correlate these two, but we have to do some extra steps to access the data - this is an annoying part of life!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Correlate</span>
<span class="kn">import</span> <span class="nn">pingouin</span> <span class="k">as</span> <span class="nn">pg</span>
<span class="n">display</span><span class="p">(</span><span class="n">pg</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">slopes</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">intercepts</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">intercepts</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">slopes</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Random intercept</span><span class="se">\n</span><span class="s1">baseline level of attractiveness&#39;</span><span class="p">,</span>
       <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Random slope</span><span class="se">\n</span><span class="s1">change in attractiveness with cosmetics&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>n</th>
      <th>r</th>
      <th>CI95%</th>
      <th>p-val</th>
      <th>BF10</th>
      <th>power</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>pearson</th>
      <td>33</td>
      <td>-0.369867</td>
      <td>[-0.63, -0.03]</td>
      <td>0.034126</td>
      <td>1.861</td>
      <td>0.577048</td>
    </tr>
  </tbody>
</table>
</div></div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Text(0.5, 0, &#39;Random intercept\nbaseline level of attractiveness&#39;),
 Text(0, 0.5, &#39;Random slope\nchange in attractiveness with cosmetics&#39;)]
</pre></div>
</div>
<img alt="../_images/3800bb3528b027a27ea3767455b249d0a808ec6b69c6b70ba0ac552f9bd28d2a.png" src="../_images/3800bb3528b027a27ea3767455b249d0a808ec6b69c6b70ba0ac552f9bd28d2a.png" />
</div>
</div>
<p>This does answer the question our industry partners had - it appears those with greater attractiveness baselines benefit less from cosmetics.</p>
</section>
</section>
<section id="variance-components-is-beauty-in-the-eye-of-the-beholder-or-a-property-of-faces">
<h2>Variance components - is beauty in the eye of the beholder, or a property of faces?<a class="headerlink" href="#variance-components-is-beauty-in-the-eye-of-the-beholder-or-a-property-of-faces" title="Link to this heading">#</a></h2>
<p>One clever property of linear mixed models is their ability to figure out how much variance in data comes from various sources. In the previous example we saw that the variation in the ratings of attractiveness with and without cosmetics could be allocated across participants, models, and changes in attractiveness with cosmetics for each model.</p>
<p>As a general rule, if a dataset has repeated measures in a group - whether its participants giving multiple ratings, or faces receiving multiple ratings, then we can use a linear mixed model to tell us how much variability in our dependent variable comes from those sources. These ‘intercept only’ models are very useful, allowing us greater insight into what’s going on in our datasets.</p>
<p>One question psychologists have been interested in for a long time is whether facial attractiveness is in the eye of the beholder, or whether it is a stable feature of faces. Traditional statistical approaches don’t really work to answer this question, but a mixed model allows us to figure out the variation we can attribute to people and to faces. Lets see how we do this.</p>
<p>We’ll borrow a dataset called the <a class="reference external" href="https://figshare.com/articles/dataset/Face_Research_Lab_London_Set/5047666?file=8542045">London Face Database</a>, an open dataset that contains attractiveness ratings of 102 faces made by 2,513 participants. This should allow us to answer our question. Lets get the data - unfortunately things are a bit slow on such a massive dataset!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read in data from link</span>
<span class="n">faces</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://figshare.com/ndownloader/files/8542045&#39;</span><span class="p">)</span>
<span class="n">faces</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rater_sex</th>
      <th>rater_sexpref</th>
      <th>rater_age</th>
      <th>X001</th>
      <th>X002</th>
      <th>X003</th>
      <th>X004</th>
      <th>X005</th>
      <th>X006</th>
      <th>X007</th>
      <th>...</th>
      <th>X137</th>
      <th>X138</th>
      <th>X139</th>
      <th>X140</th>
      <th>X141</th>
      <th>X142</th>
      <th>X143</th>
      <th>X144</th>
      <th>X172</th>
      <th>X173</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>female</td>
      <td>either</td>
      <td>17.0</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>3</td>
      <td>5</td>
      <td>...</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>5</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>female</td>
      <td>either</td>
      <td>17.0</td>
      <td>5</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>5</td>
      <td>6</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>female</td>
      <td>either</td>
      <td>17.1</td>
      <td>5</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
      <td>4</td>
      <td>...</td>
      <td>5</td>
      <td>3</td>
      <td>6</td>
      <td>1</td>
      <td>3</td>
      <td>6</td>
      <td>3</td>
      <td>6</td>
      <td>2</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>female</td>
      <td>either</td>
      <td>17.1</td>
      <td>4</td>
      <td>6</td>
      <td>5</td>
      <td>5</td>
      <td>3</td>
      <td>4</td>
      <td>5</td>
      <td>...</td>
      <td>5</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>5</td>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>female</td>
      <td>either</td>
      <td>17.2</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>...</td>
      <td>1</td>
      <td>3</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 105 columns</p>
</div></div></div>
</div>
<p>This will need reshaping to the ‘long’ format. Each row is a rater, and the columns starting with ‘X’ are the faces. We’ll need to:</p>
<ul class="simple">
<li><p>Insert a column tracking the rows, which will be our participant ID</p></li>
<li><p>Melt the data into a long format</p></li>
</ul>
<p>This is done like so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Insert a column tracking rows</span>
<span class="n">faces</span><span class="p">[</span><span class="s1">&#39;pid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">faces</span><span class="p">))</span>

<span class="c1"># Melt the data, keeping pid, rater_sex, rater_sexpref, and rater_age as identifying variables</span>
<span class="n">faces_long</span> <span class="o">=</span> <span class="n">faces</span><span class="o">.</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pid&#39;</span><span class="p">,</span> <span class="s1">&#39;rater_sex&#39;</span><span class="p">,</span> <span class="s1">&#39;rater_sexpref&#39;</span><span class="p">,</span> <span class="s1">&#39;rater_age&#39;</span><span class="p">],</span>
                        <span class="n">var_name</span><span class="o">=</span><span class="s1">&#39;face&#39;</span><span class="p">,</span>  <span class="n">value_name</span><span class="o">=</span><span class="s1">&#39;rating&#39;</span><span class="p">)</span>

<span class="c1"># Display</span>
<span class="n">display</span><span class="p">(</span><span class="n">faces_long</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pid</th>
      <th>rater_sex</th>
      <th>rater_sexpref</th>
      <th>rater_age</th>
      <th>face</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>female</td>
      <td>either</td>
      <td>17.0</td>
      <td>X001</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>female</td>
      <td>either</td>
      <td>17.0</td>
      <td>X001</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>female</td>
      <td>either</td>
      <td>17.1</td>
      <td>X001</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>female</td>
      <td>either</td>
      <td>17.1</td>
      <td>X001</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>female</td>
      <td>either</td>
      <td>17.2</td>
      <td>X001</td>
      <td>3</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>256321</th>
      <td>2508</td>
      <td>male</td>
      <td>NaN</td>
      <td>61.8</td>
      <td>X173</td>
      <td>3</td>
    </tr>
    <tr>
      <th>256322</th>
      <td>2509</td>
      <td>male</td>
      <td>NaN</td>
      <td>88.1</td>
      <td>X173</td>
      <td>3</td>
    </tr>
    <tr>
      <th>256323</th>
      <td>2510</td>
      <td>NaN</td>
      <td>men</td>
      <td>17.2</td>
      <td>X173</td>
      <td>1</td>
    </tr>
    <tr>
      <th>256324</th>
      <td>2511</td>
      <td>NaN</td>
      <td>women</td>
      <td>19.5</td>
      <td>X173</td>
      <td>3</td>
    </tr>
    <tr>
      <th>256325</th>
      <td>2512</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>33.4</td>
      <td>X173</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>256326 rows × 6 columns</p>
</div></div></div>
</div>
<p>This dataset can now be subjected to a variance partitioning approach. First we add a grouping variable which is the same for everyone, then create our variance components, one for pid and one for face.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add grouping</span>
<span class="n">faces_long</span><span class="p">[</span><span class="s1">&#39;grouping&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Variance components for faces and pid</span>
<span class="n">vc</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;faces&#39;</span><span class="p">:</span> <span class="s1">&#39;0 + C(face)&#39;</span><span class="p">,</span> 
      <span class="s1">&#39;pids&#39;</span><span class="p">:</span> <span class="s1">&#39;0 + C(pid)&#39;</span><span class="p">}</span>

<span class="c1"># Fit a model with just an intercept, note this is done by ~ 1</span>
<span class="n">intercept_only_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">mixedlm</span><span class="p">(</span><span class="s1">&#39;rating ~ 1&#39;</span><span class="p">,</span>
                                   <span class="n">groups</span><span class="o">=</span><span class="s1">&#39;grouping&#39;</span><span class="p">,</span>
                                   <span class="n">vc_formula</span><span class="o">=</span><span class="n">vc</span><span class="p">,</span>
                                   <span class="n">use_sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                   <span class="n">data</span><span class="o">=</span><span class="n">faces_long</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Summary</span>
<span class="n">intercept_only_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<tr>
       <td>Model:</td>        <td>MixedLM</td> <td>Dependent Variable:</td>    <td>rating</td>   
</tr>
<tr>
  <td>No. Observations:</td>  <td>256326</td>        <td>Method:</td>           <td>REML</td>    
</tr>
<tr>
     <td>No. Groups:</td>        <td>1</td>          <td>Scale:</td>           <td>1.1834</td>   
</tr>
<tr>
  <td>Min. group size:</td>   <td>256326</td>    <td>Log-Likelihood:</td>   <td>-390834.4643</td>
</tr>
<tr>
  <td>Max. group size:</td>   <td>256326</td>      <td>Converged:</td>           <td>Yes</td>    
</tr>
<tr>
  <td>Mean group size:</td>  <td>256326.0</td>          <td></td>                 <td></td>      
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>      <th>Coef.</th> <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>
</tr>
<tr>
  <th>Intercept</th> <td>3.019</td>   <td>0.078</td>  <td>38.737</td> <td>0.000</td>  <td>2.866</td>  <td>3.172</td>
</tr>
<tr>
  <th>faces Var</th> <td>0.590</td>   <td>0.076</td>     <td></td>      <td></td>       <td></td>       <td></td>   
</tr>
<tr>
  <th>pids Var</th>  <td>0.706</td>   <td>0.019</td>     <td></td>      <td></td>       <td></td>       <td></td>   
</tr>
</table><br/>
</div></div>
</div>
<p>From this, we can compute the proportion each source contributes to the total. First, add up the random effect variances and the error variability (the ‘scale’).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Total variance</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">intercept_only_model</span><span class="o">.</span><span class="n">vcomp</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">intercept_only_model</span><span class="o">.</span><span class="n">scale</span>

<span class="c1"># Then divide the vcomps by the total</span>
<span class="n">vcomps</span> <span class="o">=</span> <span class="n">intercept_only_model</span><span class="o">.</span><span class="n">vcomp</span> <span class="o">/</span> <span class="n">total</span>
<span class="n">vcomps</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.23803889, 0.28481472])
</pre></div>
</div>
</div>
</div>
<p>This suggests faces contribute about 24%, and participants - the eye of the beholder - contributes 28%!</p>
</section>
</section>
<section id="predictions-with-mixed-models">
<h1>Predictions with mixed models<a class="headerlink" href="#predictions-with-mixed-models" title="Link to this heading">#</a></h1>
<p>We can rely on <code class="docutils literal notranslate"><span class="pre">marginaleffects</span></code> to make predictions from models in the usual way. There is however a philosophical wrinkle when you make predictions with mixed models. Namely, what <em>kind</em> of prediction do you want?</p>
<p>A mixed model can make predictions using only the global coefficient estimates (in the summary tables). These are properly the things we want - given we know X, what is Y on average? But these ignore the sources of variability in the data. For example, a mixed model can make specific predictions about an individual participant better than a GLM can, because it knows the random effect of the participant.</p>
<p>Most of the time, predictions are focused only on the former, global effects. This is what <code class="docutils literal notranslate"><span class="pre">marginaleffects</span></code> will use when making predictions, and will ignore the random effects:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the difference in makeup</span>
<span class="n">me</span><span class="o">.</span><span class="n">predictions</span><span class="p">(</span><span class="n">cosmetics_model</span><span class="p">,</span> <span class="n">newdata</span><span class="o">=</span><span class="n">me</span><span class="o">.</span><span class="n">datagrid</span><span class="p">(</span><span class="n">cosmetics_code</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">hypothesis</span><span class="o">=</span><span class="s1">&#39;b1=b2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div><style>
.dataframe > thead > tr,
.dataframe > tbody > tr {
  text-align: right;
  white-space: pre-wrap;
}
</style>
<small>shape: (1, 8)</small><table border="1" class="dataframe"><thead><tr><th>term</th><th>estimate</th><th>std_error</th><th>statistic</th><th>p_value</th><th>s_value</th><th>conf_low</th><th>conf_high</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;b1=b2&quot;</td><td>1.161886</td><td>0.132362</td><td>8.778118</td><td>0.0</td><td>inf</td><td>0.902462</td><td>1.42131</td></tr></tbody></table></div></div></div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./7_MixedModel"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../6_Applications/QPoP%20-%20Week%206%20Exercises%20-%20Answers.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Quantitative Perspectives on Psychology</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7 - Linear mixed effects models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dealing-with-repeated-measurements">Dealing with repeated measurements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#professors-and-repeated-measurements">Professors and repeated measurements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-effects-how-mixed-models-work">Random effects - how mixed models work</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-intercepts">Random intercepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-intercepts-and-random-slopes">Random intercepts AND random slopes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-random-slope">The random slope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-complexity-with-several-random-intercepts-and-random-slopes">Building complexity with several random intercepts and random slopes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-linear-mixed-models-to-identify-individual-differences">Using linear mixed models to identify individual differences</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-components-is-beauty-in-the-eye-of-the-beholder-or-a-property-of-faces">Variance components - is beauty in the eye of the beholder, or a property of faces?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions-with-mixed-models">Predictions with mixed models</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Alex Jones, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>